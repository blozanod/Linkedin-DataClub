# -*- coding: utf-8 -*-
"""remoteok job scraper

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ssansQO9s0fWKPY-L_boR9seuK3gApiC
"""

# ==========================================
# REMOTEOK JSON SCRAPER - GOOGLE COLAB
# ==========================================
# RemoteOK provides a JSON feed - much easier than HTML!

import requests
import pandas as pd

def getting_data(keywords, jobs_shown=10):

    jobs_list = []

    try:
        search_term = keywords.lower().replace(' ', '-')
        url = f'https://remoteok.com/api?tag={search_term}'

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        response = requests.get(url, headers=headers)

        data = response.json()

        if len(data) > 1:
            jobs = data[1:]  #u have to skip the first item bc metadata?
        else:
            jobs = []

        # Extract data from each job
        for job in jobs:

             try:

                """
                https://remoteok.com/api?tag=data-science
                position = job title
                min_salary
                """
                # job_id - used url
                #COULD ALSO USE "id":"1128286"
                job_id = job.get('url', None)

                # company_name
                company_name = job.get('company', None)

                # title
                title = job.get('position', None)

                # description
                description = job.get('description', None)

                # max_salary
                max_salary = job.get('salary_max', None)

                # pay_period - couldn't find
                pay_period = None

                # location
                location = job.get('location', None)

                # company_id
                company_id = None

                # views
                views = None

                # med_salary
                med_salary = None

                job_data = {
                    'job_id': job_id,
                    'company_name': company_name,
                    'title': title,
                    'description': description,
                    'max_salary': max_salary,
                    'pay_period': pay_period,
                    'location': location,
                    'company_id': company_id,
                    'views': views,
                    'med_salary': med_salary
                }

                jobs_list.append(job_data)

             except Exception as e:
                print(f"{e}")
                continue

    except Exception as e:
        print(f"{e}")


    df = pd.DataFrame(jobs_list)

    return df

'''
#RUN UR SCRAPER i hope it works
# - your older brother

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', 50)


keywords = "engineer"
jobs_shown = 999999

df = getting_data(keywords, jobs_shown=jobs_shown)

print(df)
'''

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', 50)


keywords = "engineer"
jobs_shown = 999999

df = getting_data(keywords, jobs_shown=jobs_shown)

print(df)

#sqlalchemy

from sqlalchemy import create_engine

keywords = 'data analyst'
jobs_shown = 10

df = getting_data(keywords, jobs_shown=jobs_shown)
engine = create_engine('sqlite:///jobs.db')
df.to_sql('remoteokjobs', engine, if_exists='replace', index=False)